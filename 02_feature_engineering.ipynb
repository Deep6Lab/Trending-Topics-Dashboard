{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12937497",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook prepares data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6a2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4f1368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Year_Scaled</th>\n",
       "      <th>Year_STD</th>\n",
       "      <th>Month</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Cleaned</th>\n",
       "      <th>Abstract Length</th>\n",
       "      <th>Keywords_Cleaned</th>\n",
       "      <th>Number of Keywords</th>\n",
       "      <th>Month_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Capital structure', 'Corporate taxation', 'D...</td>\n",
       "      <td>Absent theoretical guidance, empiricists have ...</td>\n",
       "      <td>absent theoret guidance empiricist forc reli u...</td>\n",
       "      <td>1047</td>\n",
       "      <td>['capit structur', 'corpor taxat', 'difference...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Credit spreads', 'LBO risk', 'Structural mod...</td>\n",
       "      <td>Recent decades have witnessed several waves of...</td>\n",
       "      <td>recent decad wit sever wave buyout activity fi...</td>\n",
       "      <td>580</td>\n",
       "      <td>['credit spread', 'lbo risk', 'structur model'...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Fire sales', 'Liquidity management', 'Mutual...</td>\n",
       "      <td>We develop three novel measures of the incenti...</td>\n",
       "      <td>develop three novel measur incent equiti mutua...</td>\n",
       "      <td>586</td>\n",
       "      <td>['fire sale', 'liquid manag', 'mutual fund']</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Asset pricing', 'Leverage constraints', 'Lot...</td>\n",
       "      <td>We test whether the low-risk effect is driven ...</td>\n",
       "      <td>test whether lowrisk effect driven leverag con...</td>\n",
       "      <td>861</td>\n",
       "      <td>['asset price', 'leverag constraint', 'lotteri...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Gender gap', 'Entrepreneurship', 'Angel inve...</td>\n",
       "      <td>We study whether early stage investors have ge...</td>\n",
       "      <td>studi whether earli stage investor gender bias...</td>\n",
       "      <td>742</td>\n",
       "      <td>['gender gap', 'entrepreneurship', 'angel inve...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Year_Scaled    Year_STD  Month  \\\n",
       "0  2020     1.243352  169.971142  March   \n",
       "1  2020     1.243352  169.971142  March   \n",
       "2  2020     1.243352  169.971142  March   \n",
       "3  2020     1.243352  169.971142  March   \n",
       "4  2020     1.243352  169.971142  March   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  ['Capital structure', 'Corporate taxation', 'D...   \n",
       "1  ['Credit spreads', 'LBO risk', 'Structural mod...   \n",
       "2  ['Fire sales', 'Liquidity management', 'Mutual...   \n",
       "3  ['Asset pricing', 'Leverage constraints', 'Lot...   \n",
       "4  ['Gender gap', 'Entrepreneurship', 'Angel inve...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Absent theoretical guidance, empiricists have ...   \n",
       "1  Recent decades have witnessed several waves of...   \n",
       "2  We develop three novel measures of the incenti...   \n",
       "3  We test whether the low-risk effect is driven ...   \n",
       "4  We study whether early stage investors have ge...   \n",
       "\n",
       "                                    Abstract_Cleaned  Abstract Length  \\\n",
       "0  absent theoret guidance empiricist forc reli u...             1047   \n",
       "1  recent decad wit sever wave buyout activity fi...              580   \n",
       "2  develop three novel measur incent equiti mutua...              586   \n",
       "3  test whether lowrisk effect driven leverag con...              861   \n",
       "4  studi whether earli stage investor gender bias...              742   \n",
       "\n",
       "                                    Keywords_Cleaned  Number of Keywords  \\\n",
       "0  ['capit structur', 'corpor taxat', 'difference...                   5   \n",
       "1  ['credit spread', 'lbo risk', 'structur model'...                   4   \n",
       "2       ['fire sale', 'liquid manag', 'mutual fund']                   3   \n",
       "3  ['asset price', 'leverag constraint', 'lotteri...                   5   \n",
       "4  ['gender gap', 'entrepreneurship', 'angel inve...                   4   \n",
       "\n",
       "   Month_Cleaned  \n",
       "0              3  \n",
       "1              3  \n",
       "2              3  \n",
       "3              3  \n",
       "4              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-processed data\n",
    "df = pd.read_csv('data/data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f92e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a data pipeline\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),                                 # bag-of-words\n",
    "                     ('lda', LatentDirichletAllocation(n_components=50,           # topic modeling\n",
    "                                                       random_state=42,\n",
    "                                                       topic_word_prior=None)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('svd', TruncatedSVD(n_components=10, random_state=42)),     # components reduction\n",
    "                     ('to_dense', DenseTransformer())])                           # data transform\n",
    "\n",
    "# build data vector representation of abstract\n",
    "x_vector = pipeline.fit_transform(df.Abstract_Cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3faff8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22002264,  2.2219857 , -1.01177663, ..., -0.73937831,\n",
       "        -1.06955482, -1.67230182],\n",
       "       [ 1.02046173,  2.82636214,  0.48123842, ..., -0.16985951,\n",
       "         1.05417153,  0.10407414],\n",
       "       [ 0.30568027,  0.80914701, -0.70299143, ...,  4.07895096,\n",
       "        -0.01572586,  0.83661459],\n",
       "       ...,\n",
       "       [ 3.05213089, -0.84898762,  0.13323143, ..., -0.03871609,\n",
       "         0.00791277, -0.12780114],\n",
       "       [ 0.27029913,  0.63435036, -1.07016025, ...,  0.27322576,\n",
       "        -0.32526024, -0.50543736],\n",
       "       [ 1.23598864,  1.26528023, -0.87203966, ..., -0.28934377,\n",
       "         1.11214526,  1.32729393]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize x_vector\n",
    "x_vector = Normalizer().fit_transform(x_vector)\n",
    "df_x_vector = pd.DataFrame(x_vector, index=None)\n",
    "df_x_vector = df_x_vector / df_x_vector.std()\n",
    "x_vector = df_x_vector.to_numpy()\n",
    "\n",
    "# display x_vector\n",
    "x_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba81127",
   "metadata": {},
   "source": [
    "### Build Terms Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01ca5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "import json\n",
    "\n",
    "# create TF-IDF transformer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df.Abstract_Cleaned)\n",
    "terms_sparse_matrix = tfidf.transform(df.Abstract_Cleaned)\n",
    "terms_label = tfidf.get_feature_names()\n",
    "\n",
    "# save data\n",
    "# to load sparse matrix: sparse_matrix = scipy.sparse.load_npz('/tmp/sparse_matrix.npz')\n",
    "scipy.sparse.save_npz('data/terms_sparse_matrix.npz', terms_sparse_matrix)\n",
    "\n",
    "# save term labels\n",
    "with open(\"data/terms_label.txt\", \"w\") as fp:\n",
    "    json.dump(terms_label, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25165a1",
   "metadata": {},
   "source": [
    "## Save Data for Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e39da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save x_vector\n",
    "with open('data/x_vector.npy', 'wb') as file:\n",
    "    np.save(file, x_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
