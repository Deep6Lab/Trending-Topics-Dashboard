{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12937497",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook prepares data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6a2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde74ca",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4f1368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Year_Scaled</th>\n",
       "      <th>Year_STD</th>\n",
       "      <th>Month</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Cleaned</th>\n",
       "      <th>Abstract Length</th>\n",
       "      <th>Keywords_Cleaned</th>\n",
       "      <th>Number of Keywords</th>\n",
       "      <th>Month_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Capital structure', 'Corporate taxation', 'D...</td>\n",
       "      <td>Absent theoretical guidance, empiricists have ...</td>\n",
       "      <td>absent theoret guidance empiricist forc reli u...</td>\n",
       "      <td>1047</td>\n",
       "      <td>['capit structur', 'corpor taxat', 'difference...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Credit spreads', 'LBO risk', 'Structural mod...</td>\n",
       "      <td>Recent decades have witnessed several waves of...</td>\n",
       "      <td>recent decad wit sever wave buyout activity fi...</td>\n",
       "      <td>580</td>\n",
       "      <td>['credit spread', 'lbo risk', 'structur model'...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Fire sales', 'Liquidity management', 'Mutual...</td>\n",
       "      <td>We develop three novel measures of the incenti...</td>\n",
       "      <td>develop three novel measur incent equiti mutua...</td>\n",
       "      <td>586</td>\n",
       "      <td>['fire sale', 'liquid manag', 'mutual fund']</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Asset pricing', 'Leverage constraints', 'Lot...</td>\n",
       "      <td>We test whether the low-risk effect is driven ...</td>\n",
       "      <td>test whether lowrisk effect driven leverag con...</td>\n",
       "      <td>861</td>\n",
       "      <td>['asset price', 'leverag constraint', 'lotteri...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.243352</td>\n",
       "      <td>169.971142</td>\n",
       "      <td>March</td>\n",
       "      <td>['Gender gap', 'Entrepreneurship', 'Angel inve...</td>\n",
       "      <td>We study whether early stage investors have ge...</td>\n",
       "      <td>studi whether earli stage investor gender bias...</td>\n",
       "      <td>742</td>\n",
       "      <td>['gender gap', 'entrepreneurship', 'angel inve...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Year_Scaled    Year_STD  Month  \\\n",
       "0  2020     1.243352  169.971142  March   \n",
       "1  2020     1.243352  169.971142  March   \n",
       "2  2020     1.243352  169.971142  March   \n",
       "3  2020     1.243352  169.971142  March   \n",
       "4  2020     1.243352  169.971142  March   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  ['Capital structure', 'Corporate taxation', 'D...   \n",
       "1  ['Credit spreads', 'LBO risk', 'Structural mod...   \n",
       "2  ['Fire sales', 'Liquidity management', 'Mutual...   \n",
       "3  ['Asset pricing', 'Leverage constraints', 'Lot...   \n",
       "4  ['Gender gap', 'Entrepreneurship', 'Angel inve...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Absent theoretical guidance, empiricists have ...   \n",
       "1  Recent decades have witnessed several waves of...   \n",
       "2  We develop three novel measures of the incenti...   \n",
       "3  We test whether the low-risk effect is driven ...   \n",
       "4  We study whether early stage investors have ge...   \n",
       "\n",
       "                                    Abstract_Cleaned  Abstract Length  \\\n",
       "0  absent theoret guidance empiricist forc reli u...             1047   \n",
       "1  recent decad wit sever wave buyout activity fi...              580   \n",
       "2  develop three novel measur incent equiti mutua...              586   \n",
       "3  test whether lowrisk effect driven leverag con...              861   \n",
       "4  studi whether earli stage investor gender bias...              742   \n",
       "\n",
       "                                    Keywords_Cleaned  Number of Keywords  \\\n",
       "0  ['capit structur', 'corpor taxat', 'difference...                   5   \n",
       "1  ['credit spread', 'lbo risk', 'structur model'...                   4   \n",
       "2       ['fire sale', 'liquid manag', 'mutual fund']                   3   \n",
       "3  ['asset price', 'leverag constraint', 'lotteri...                   5   \n",
       "4  ['gender gap', 'entrepreneurship', 'angel inve...                   4   \n",
       "\n",
       "   Month_Cleaned  \n",
       "0              3  \n",
       "1              3  \n",
       "2              3  \n",
       "3              3  \n",
       "4              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-processed data\n",
    "df = pd.read_csv('data/data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629d893",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019b1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [17:20<00:00, 208.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA</th>\n",
       "      <th>LDA_topic_word</th>\n",
       "      <th>SVD</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.423390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.418624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.417683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.415258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.407064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.407013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.404993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.403532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.400660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.398933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LDA  LDA_topic_word  SVD     Score\n",
       "41   50             NaN   10  0.423390\n",
       "42   50             NaN   12  0.418624\n",
       "24   40             NaN    8  0.417683\n",
       "8    30             NaN    8  0.415258\n",
       "10   30             NaN   12  0.407064\n",
       "27   40             NaN   15  0.407013\n",
       "9    30             NaN   10  0.404993\n",
       "25   40             NaN   10  0.403532\n",
       "11   30             NaN   15  0.400660\n",
       "43   50             NaN   15  0.398933"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "lda_n_compo = [20, 30, 40, 50, 60]     # a list of LDA's number of components\n",
    "lda_topic_word = [None, 15, 20, 25]    # a list of number of terms\n",
    "svd = [8, 10, 12, 15]                  # a list of SVD's number of components\n",
    "params_result = []\n",
    "\n",
    "# iterate through every item in the lda_n_compo list\n",
    "# run KMeans model for each selected set of parameters\n",
    "for ldn in tqdm(lda_n_compo):\n",
    "    for ldt in lda_topic_word: \n",
    "        for sn in svd:\n",
    "            try:\n",
    "                if sn >= ldn or ldt >= ldn:\n",
    "                    continue\n",
    "            except TypeError:\n",
    "                pass\n",
    "\n",
    "            # build a data pipeline\n",
    "            p = [('vect', CountVectorizer()),\n",
    "                 ('lda', LatentDirichletAllocation(n_components=ldn,random_state=42,topic_word_prior=ldt)),\n",
    "                 ('tfidf', TfidfTransformer())]\n",
    "            \n",
    "            # include dimensionality reduction in the data pipeline\n",
    "            if sn > 0:\n",
    "                p.append(('svd', TruncatedSVD(n_components=sn)))\n",
    "            p.append(('to_dense', DenseTransformer()))\n",
    "            c_pipe = Pipeline(p)\n",
    "            \n",
    "            # create a vector representation of abstracts\n",
    "            vec = c_pipe.fit_transform(df.Abstract_Cleaned)\n",
    "            # normalize vector\n",
    "            vec = Normalizer().fit_transform(vec)\n",
    "            vec = pd.DataFrame(vec, index=None)\n",
    "            vec = vec / vec.std()\n",
    "            vec = vec.to_numpy()\n",
    "            \n",
    "            # build a KMeans model and compute Silhouette score\n",
    "            model = KMeans(n_clusters=15,random_state=42)\n",
    "            predicted = model.fit_predict(vec)\n",
    "            score = silhouette_score(vec, predicted)\n",
    "            params_result.append((ldn, ldt, sn, score))\n",
    "\n",
    "# create a dataframe of the parameter tuning results\n",
    "# the best model should have a highest Silhouette score\n",
    "df_params = pd.DataFrame(params_result, columns=['LDA','LDA_topic_word','SVD','Score'])\n",
    "df_params.sort_values(['Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e75619d",
   "metadata": {},
   "source": [
    "## Build Vector Representation of Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f92e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a data pipeline\n",
    "pipeline = Pipeline([('vect', CountVectorizer()),                                 # bag-of-words\n",
    "                     ('lda', LatentDirichletAllocation(n_components=50,           # topic modeling\n",
    "                                                       random_state=42,\n",
    "                                                       topic_word_prior=None)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('svd', TruncatedSVD(n_components=10, random_state=42)),     # components reduction\n",
    "                     ('to_dense', DenseTransformer())])                           # data transform\n",
    "\n",
    "# build data vector representation of abstracts\n",
    "x_vector = pipeline.fit_transform(df.Abstract_Cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3faff8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22002264,  2.2219857 , -1.01177663, ..., -0.73937831,\n",
       "        -1.06955482, -1.67230182],\n",
       "       [ 1.02046173,  2.82636214,  0.48123842, ..., -0.16985951,\n",
       "         1.05417153,  0.10407414],\n",
       "       [ 0.30568027,  0.80914701, -0.70299143, ...,  4.07895096,\n",
       "        -0.01572586,  0.83661459],\n",
       "       ...,\n",
       "       [ 3.05213089, -0.84898762,  0.13323143, ..., -0.03871609,\n",
       "         0.00791277, -0.12780114],\n",
       "       [ 0.27029913,  0.63435036, -1.07016025, ...,  0.27322576,\n",
       "        -0.32526024, -0.50543736],\n",
       "       [ 1.23598864,  1.26528023, -0.87203966, ..., -0.28934377,\n",
       "         1.11214526,  1.32729393]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize x_vector\n",
    "x_vector = Normalizer().fit_transform(x_vector)\n",
    "df_x_vector = pd.DataFrame(x_vector, index=None)\n",
    "df_x_vector = df_x_vector / df_x_vector.std()\n",
    "x_vector = df_x_vector.to_numpy()\n",
    "\n",
    "# display x_vector\n",
    "x_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e39da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save x_vector for model development\n",
    "with open('data/x_vector.npy', 'wb') as file:\n",
    "    np.save(file, x_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba81127",
   "metadata": {},
   "source": [
    "### Build Terms Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01ca5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse\n",
    "import json\n",
    "\n",
    "# create TF-IDF transformer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(df.Abstract_Cleaned)\n",
    "\n",
    "# build terms matrix for entire corpus\n",
    "terms_sparse_matrix = tfidf.transform(df.Abstract_Cleaned)\n",
    "\n",
    "# save terms sparse matrix\n",
    "# to load sparse matrix: sparse_matrix = scipy.sparse.load_npz('data/terms_sparse_matrix.npz')\n",
    "scipy.sparse.save_npz('data/terms_sparse_matrix.npz', terms_sparse_matrix)\n",
    "\n",
    "# get term label for each item in the term matrix and save result to a text file\n",
    "terms_label = tfidf.get_feature_names()\n",
    "\n",
    "# save term labels\n",
    "with open(\"data/terms_label.txt\", \"w\") as fp:\n",
    "    json.dump(terms_label, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
